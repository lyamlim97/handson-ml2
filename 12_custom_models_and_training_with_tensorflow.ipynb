{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 12 – Custom Models and Training with TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code in chapter 12._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/12_custom_models_and_training_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-ml2/blob/master/12_custom_models_and_training_with_tensorflow.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.4 is required in this notebook\n",
    "# Earlier 2.x versions will mostly work the same, but with a few bugs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# assert tf.__version__ >= \"2.4\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors and operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42) # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `keras.backend`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "K = keras.backend\n",
    "K.square(K.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From/To NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conflicting Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(b\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "tf.strings.length(b, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2])>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(p, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
       " [99, 97, 102, 102, 232], [21654, 21857]]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
      " [99, 97, 102, 102, 232], [21654, 21857]]>\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragged tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 67 111 102 102 101 101], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232]]>\n"
     ]
    }
   ],
   "source": [
    "print(r[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
      " [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>\n"
     ]
    }
   ],
   "source": [
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "print(tf.concat([r, r2], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101, 71],\n",
      " [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>\n"
     ]
    }
   ],
   "source": [
    "r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])\n",
    "print(tf.concat([r, r3], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=array([b'DEF', b'G', b'', b'HI'], dtype=object)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(r3, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,     0,     0],\n",
       "       [   67,   111,   102,   102,   101,   101],\n",
       "       [   99,    97,   102,   102,   232,     0],\n",
       "       [21654, 21857,     0,     0,     0,     0]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
    "                    values=[1., 2., 3.],\n",
    "                    dense_shape=[3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = s * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s3 = s + 1.\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "s5 = tf.SparseTensor(indices=[[0, 2], [0, 1]],\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])\n",
    "print(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{function_node __wrapped__SparseToDense_device_/job:localhost/replica:0/task:0/device:GPU:0}} indices[1] is out of order. Many sparse ops require sorted indices.\n",
      "  Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      "\n",
      "\t [[{{node SparseToDense}}]] [Op:SparseToDense]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 2,  3,  4,  5,  6,  7],\n",
       "       [ 0,  7,  9, 10,  0,  0]])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "tf.sparse.to_dense(tf.sets.union(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[2, 3, 7],\n",
       "       [7, 0, 0]])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.difference(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 0],\n",
       "       [0, 9]])>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.intersection(set1, set2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v[1] = [7., 8., 9.]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]],\n",
    "                    updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[4., 5., 6.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_delta = tf.IndexedSlices(values=[[1., 2., 3.], [4., 5., 6.]],\n",
    "                                indices=[1, 0])\n",
    "v.scatter_update(sparse_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 3., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, variance = tf.nn.moments(array.stack(), axes=0)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.6666665, 8.666667 ], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading and preparing the California housing dataset. We first load it, then split it into a training set, a validation set and a test set, and finally we scale it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 9ms/step - loss: 0.5712 - mae: 0.9310 - val_loss: 0.2931 - val_mae: 0.5862\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2127 - mae: 0.5079 - val_loss: 0.2438 - val_mae: 0.5320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2367a7fd540>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/Loading Models with Custom Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
    "                                custom_objects={\"huber_fn\": huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2019 - mae: 0.4927 - val_loss: 0.1995 - val_mae: 0.4816\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.1964 - mae: 0.4851 - val_loss: 0.1833 - val_mae: 0.4675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2367a88bbb0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 9ms/step - loss: 0.2170 - mae: 0.4852 - val_loss: 0.2209 - val_mae: 0.4720\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2133 - mae: 0.4799 - val_loss: 0.2132 - val_mae: 0.4733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2367bb66290>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_threshold_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 9ms/step - loss: 0.2096 - mae: 0.4765 - val_loss: 0.2235 - val_mae: 0.4685\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2076 - mae: 0.4715 - val_loss: 0.2055 - val_mae: 0.4649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2367aa55840>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 9ms/step - loss: 0.7530 - mae: 0.9372 - val_loss: 0.3231 - val_mae: 0.5485\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2413 - mae: 0.5119 - val_loss: 0.2650 - val_mae: 0.5144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2367cdca950>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
    "                                custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2292 - mae: 0.5008 - val_loss: 0.2090 - val_mae: 0.4749\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2232 - mae: 0.4937 - val_loss: 0.2132 - val_mae: 0.4794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x236795cef80>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z): # return value is just tf.nn.softplus(z)\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(1, activation=my_softplus,\n",
    "                           kernel_initializer=my_glorot_initializer,\n",
    "                           kernel_regularizer=my_l1_regularizer,\n",
    "                           kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=my_l1_regularizer,\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 1.6240 - mae: 0.9329 - val_loss: 0.6919 - val_mae: 0.5332\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.5790 - mae: 0.5199 - val_loss: 0.6090 - val_mae: 0.4957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2367fed6b00>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"my_l1_regularizer\": my_l1_regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 5s 10ms/step - loss: 1.8483 - mae: 0.9767 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.7006 - mae: 0.5423 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x235280b2e60>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"MyL1Regularizer\": MyL1Regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 8ms/step - loss: 2.3389 - huber_fn: 0.8584\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.6273 - huber_fn: 0.2650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2352820c4c0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: if you use the same function as the loss and a metric, you may be surprised to see different results. This is generally just due to floating point precision errors: even though the mathematical equations are equivalent, the operations are not run in the same order, which can lead to small differences. Moreover, when using sample weights, there's more than just precision errors:\n",
    "* the loss since the start of the epoch is the mean of all batch losses seen so far. Each batch loss is the sum of the weighted instance losses divided by the _batch size_ (not the sum of weights, so the batch loss is _not_ the weighted mean of the losses).\n",
    "* the metric since the start of the epoch is equal to the sum of weighted instance losses divided by sum of all weights seen so far. In other words, it is the weighted mean of all the instance losses. Not the same thing.\n",
    "\n",
    "If you do the math, you will find that loss = metric * mean of sample weights (plus some floating point precision error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 8ms/step - loss: 0.1136 - huber_fn: 0.2303\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.1092 - huber_fn: 0.2218\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11355339735746384, 0.11429158534048744)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"huber_fn\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a streaming metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = HuberMetric(2.)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2²/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "m(tf.constant([[2.]]), tf.constant([[10.]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
    "\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=21.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=3.0>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=0.0>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_states()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the `HuberMetric` class works well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 8ms/step - loss: 0.8387 - huber_metric: 0.8387\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.2490 - huber_metric: 0.2490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x235294d4ac0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_metric.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0),\n",
    "                                                \"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2340 - huber_metric: 0.2340\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.2268 - huber_metric: 0.2268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23528389f00>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: In TF 2.2, tf.keras adds an extra first metric in `model.metrics` at position 0 (see [TF issue #38150](https://github.com/tensorflow/tensorflow/issues/38150)). This forces us to use `model.metrics[-1]` rather than `model.metrics[0]` to access the `HuberMetric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it works fine! More simply, we could have created the class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class handles shapes better, and it also supports sample weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 8ms/step - loss: 0.4333 - HuberMetric: 0.8732\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.1291 - HuberMetric: 0.2603\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32),\n",
    "                    epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4333159923553467, 0.43331606073497597)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"HuberMetric\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_metric_v2.h5\",\n",
    "                                custom_objects={\"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.2401 - HuberMetric: 0.2401\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.2257 - HuberMetric: 0.2257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23529508a60>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787948, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an exponential layer at the output of a regression model can be useful if the values to predict are positive and with very different scales (e.g., 0.001, 10., 10000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7220 - val_loss: 0.4054\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7784 - val_loss: 0.4205\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4350 - val_loss: 0.3593\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4025 - val_loss: 0.3526\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3822 - val_loss: 0.3531\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3737722337245941"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 8ms/step - loss: 1.7466 - val_loss: 0.7562\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.5804 - val_loss: 0.5266\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.5030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5029750466346741"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_layer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_layer.h5\",\n",
    "                                custom_objects={\"MyDense\": MyDense})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        print(\"X1.shape: \", X1.shape ,\" X2.shape: \", X2.shape) # Debugging of custom layer\n",
    "        return X1 + X2, X1 * X2\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our custom layer can be called using the functional API like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 2)  X2.shape:  (None, 2)\n"
     ]
    }
   ],
   "source": [
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `call()` method receives symbolic inputs, whose shape is only partially specified (at this stage, we don't know the batch size, which is why the first dimension is `None`):\n",
    "\n",
    "We can also pass actual data to the custom layer. To test this, let's split each dataset's inputs into two parts, with four features each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11610, 4), (11610, 4))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data(data):\n",
    "    columns_count = data.shape[-1]\n",
    "    half = columns_count // 2\n",
    "    return data[:, :half], data[:, half:]\n",
    "\n",
    "X_train_scaled_A, X_train_scaled_B = split_data(X_train_scaled)\n",
    "X_valid_scaled_A, X_valid_scaled_B = split_data(X_valid_scaled)\n",
    "X_test_scaled_A, X_test_scaled_B = split_data(X_test_scaled)\n",
    "\n",
    "# Printing the splitted data shapes\n",
    "X_train_scaled_A.shape, X_train_scaled_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now notice that the shapes are fully specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (11610, 4)  X2.shape:  (11610, 4)\n"
     ]
    }
   ],
   "source": [
    "outputs1, outputs2 = MyMultiLayer()((X_train_scaled_A, X_train_scaled_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a more complete model using the functional API (this is just a toy example, don't expect awesome performance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_A = keras.layers.Input(shape=X_train_scaled_A.shape[-1])\n",
    "input_B = keras.layers.Input(shape=X_train_scaled_B.shape[-1])\n",
    "hidden_A, hidden_B = MyMultiLayer()((input_A, input_B))\n",
    "hidden_A = keras.layers.Dense(30, activation='selu')(hidden_A)\n",
    "hidden_B = keras.layers.Dense(30, activation='selu')(hidden_B)\n",
    "concat = keras.layers.Concatenate()((hidden_A, hidden_B))\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "359/363 [============================>.] - ETA: 0s - loss: 2.2718X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "363/363 [==============================] - 4s 9ms/step - loss: 2.2591 - val_loss: 3.6758\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 1.0599 - val_loss: 1.3639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2352aaaa4d0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit((X_train_scaled_A, X_train_scaled_B), y_train, epochs=2,\n",
    "          validation_data=((X_valid_scaled_A, X_valid_scaled_B), y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a layer with a different behavior during training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple model that uses this custom layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    AddGaussianNoise(stddev=1.0),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 4s 8ms/step - loss: 2.4983 - val_loss: 0.8180\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.9956 - val_loss: 0.7761\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.7509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7509446144104004"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_scaled = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 8s 16ms/step - loss: 3.0497\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 6s 15ms/step - loss: 0.7035\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 5s 14ms/step - loss: 0.8554\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 5s 15ms/step - loss: 0.4643\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 5s 15ms/step - loss: 0.4673\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.4662\n",
      "162/162 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn, dense_2_layer_call_and_return_conditional_losses, dense_3_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_custom_model.ckpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_custom_model.ckpt\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_custom_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_custom_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 7s 15ms/step - loss: 0.6165\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 5s 15ms/step - loss: 0.4111\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 5s 14ms/step - loss: 0.5538\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.5092\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.4196\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have defined the model using the sequential API instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = ResidualBlock(2, 30)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    block1, block1, block1, block1,\n",
    "    ResidualBlock(2, 30),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 6s 11ms/step - loss: 1.1084\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 4s 12ms/step - loss: 0.5291\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.6000\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.3859\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 4s 11ms/step - loss: 0.4118\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.6378\n",
      "162/162 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and Metrics Based on Model Internals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: the following code has two differences with the code in the book:\n",
    "1. It creates a `keras.metrics.Mean()` metric in the constructor and uses it in the `call()` method to track the mean reconstruction loss. Since we only want to do this during training, we add a `training` argument to the `call()` method, and if `training` is `True`, then we update `reconstruction_mean` and we call `self.add_metric()` to ensure it's displayed properly.\n",
    "2. Due to an issue introduced in TF 2.2 ([#46858](https://github.com/tensorflow/tensorflow/issues/46858)), we must not call `super().build()` inside the `build()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        #super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 6s 13ms/step - loss: 0.7117 - reconstruction_error: 0.8977\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 5s 13ms/step - loss: 0.4108 - reconstruction_error: 0.3887\n",
      "162/162 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Gradients with Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "try:\n",
    "    dz_dw2 = tape.gradient(z, w2)\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2) # works now!\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1, dz_dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tape.gradient([z1, z2, z3], [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tf.reduce_sum(tf.stack([tape.gradient(z, [w1, w2]) for z in (z1, z2, z3)]), axis=0)\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
    "            for jacobian in jacobians]\n",
    "del hessian_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=nan>]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(100.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.exp(tf.constant(30., dtype=tf.float32)) + 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([100.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def my_softplus_gradients(grad):\n",
    "        return grad / (1 + 1 / exp)\n",
    "    return tf.math.log(exp + 1), my_softplus_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_better_softplus(z):\n",
    "    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_better_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Gradients Using Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=l2_reg),\n",
    "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
    "          end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fancier version with a progress bar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 3500/10000 [=>....]'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progress_bar(3500, 10000, size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 [==============================] - mean: 1.9825 - mean_absolute_error: 0.60856\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - mean: 0.8472 - mean_absolute_error: 0.5402\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - mean: 0.6779 - mean_absolute_error: 0.5140\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - mean: 0.6686 - mean_absolute_error: 0.5195\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - mean: 0.6488 - mean_absolute_error: 0.5210\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a24f02c4cd421385181e28fb485804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e79d3f6e334264b0c369f554d13a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e9158874994d8f93ef8fdd03662b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094d34e85aa64d68a32b7ad4e2c0f85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44e91d631d0490f88dd4410d010696e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfa413703a6473b8aea6c097f6b5b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    from tqdm.notebook import trange\n",
    "    from collections import OrderedDict\n",
    "    with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "        for epoch in epochs:\n",
    "            with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "                for step in steps:\n",
    "                    X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        y_pred = model(X_batch)\n",
    "                        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                        loss = tf.add_n([main_loss] + model.losses)\n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    for variable in model.variables:\n",
    "                        if variable.constraint is not None:\n",
    "                            variable.assign(variable.constraint(variable))                    \n",
    "                    status = OrderedDict()\n",
    "                    mean_loss(loss)\n",
    "                    status[\"loss\"] = mean_loss.result().numpy()\n",
    "                    for metric in metrics:\n",
    "                        metric(y_batch, y_pred)\n",
    "                        status[metric.name] = metric.result().numpy()\n",
    "                    steps.set_postfix(status)\n",
    "            for metric in [mean_loss] + metrics:\n",
    "                metric.reset_states()\n",
    "except ImportError as ex:\n",
    "    print(\"To run this cell, please install tqdm, ipywidgets and restart Jupyter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x2352b66a2c0>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Functions and Concrete Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x2352b669780>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function is tf_cube.get_concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Function Definitions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x2352b669780>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = concrete_function.graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op = ops[2]\n",
    "list(pow_op.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'pow:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_operation_by_name('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Identity:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_tensor_by_name('Identity:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"__inference_cube_1083107\"\n",
       "input_arg {\n",
       "  name: \"x\"\n",
       "  type: DT_FLOAT\n",
       "}\n",
       "output_arg {\n",
       "  name: \"identity\"\n",
       "  type: DT_FLOAT\n",
       "}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.function_def.signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How TF Functions Trace Python Functions to Extract Their Computation Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    print(\"print:\", x)\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: 2\n",
      "print: 3\n",
      "print: Tensor(\"x:0\", shape=(1, 2), dtype=float32)\n",
      "print: Tensor(\"x:0\", shape=(2, 2), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x0000023685F07490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x0000023685F07490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(3, 2), dtype=float32)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function tf_cube at 0x0000023685F07490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function tf_cube at 0x0000023685F07490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(2)\n",
    "result = tf_cube(3)\n",
    "result = tf_cube(tf.constant([[1., 2.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[3., 4.], [5., 6.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[7., 8.], [9., 10.], [11., 12.]])) # New shape: trace!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to specify a particular input signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images):\n",
    "    print(\"Tracing\", images)\n",
    "    return images[:, ::2, ::2] # drop half the rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing Tensor(\"images:0\", shape=(None, 28, 28), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "preprocessed_images = shrink(img_batch_1) # Traces the function.\n",
    "preprocessed_images = shrink(img_batch_2) # Reuses the same concrete function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor(\n",
      "[[[0.7413678  0.62854624]\n",
      "  [0.01738465 0.3431449 ]]\n",
      "\n",
      " [[0.51063764 0.3777541 ]\n",
      "  [0.07321596 0.02137029]]], shape=(2, 2, 2), dtype=float32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None)).\n"
     ]
    }
   ],
   "source": [
    "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
    "try:\n",
    "    preprocessed_images = shrink(img_batch_3)  # rejects unexpected types or shapes\n",
    "except ValueError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Autograph To Capture Control Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"static\" `for` loop using `range()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=AddV2>,\n",
       " <tf.Operation 'add_2/y' type=Const>,\n",
       " <tf.Operation 'add_2' type=AddV2>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=AddV2>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=AddV2>,\n",
       " <tf.Operation 'add_5/y' type=Const>,\n",
       " <tf.Operation 'add_5' type=AddV2>,\n",
       " <tf.Operation 'add_6/y' type=Const>,\n",
       " <tf.Operation 'add_6' type=AddV2>,\n",
       " <tf.Operation 'add_7/y' type=Const>,\n",
       " <tf.Operation 'add_7' type=AddV2>,\n",
       " <tf.Operation 'add_8/y' type=Const>,\n",
       " <tf.Operation 'add_8' type=AddV2>,\n",
       " <tf.Operation 'add_9/y' type=Const>,\n",
       " <tf.Operation 'add_9' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"dynamic\" loop using `tf.while_loop()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    condition = lambda i, x: tf.less(i, 10)\n",
    "    body = lambda i, x: (tf.add(i, 1), tf.add(x, 1))\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"dynamic\" `for` loop using `tf.range()` (captured by autograph):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x = x + 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'range/start' type=Const>,\n",
       " <tf.Operation 'range/limit' type=Const>,\n",
       " <tf.Operation 'range/delta' type=Const>,\n",
       " <tf.Operation 'range' type=Range>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'mod' type=FloorMod>,\n",
       " <tf.Operation 'zeros_like' type=Const>,\n",
       " <tf.Operation 'NotEqual' type=NotEqual>,\n",
       " <tf.Operation 'Cast' type=Cast>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'zeros_like_1' type=Const>,\n",
       " <tf.Operation 'Maximum' type=Maximum>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Variables and Other Resources in TF Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(counter, c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment(counter)\n",
    "increment(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"counter\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function(counter).function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment()\n",
    "increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"assignaddvariableop_resource\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function().function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.counter = tf.Variable(0)\n",
    "\n",
    "    @tf.function\n",
    "    def increment(self, c=1):\n",
    "        return self.counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter()\n",
    "c.increment()\n",
    "c.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__add(x):\n",
      "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (x,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal x\n",
      "            (x,) = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal x\n",
      "            i = itr\n",
      "            x = ag__.ld(x)\n",
      "            x += 1\n",
      "        i = ag__.Undefined('i')\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(x)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x += 1\n",
    "    return x\n",
    "\n",
    "print(tf.autograph.to_code(add_10.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tf_code(func):\n",
    "    from IPython.display import display, Markdown\n",
    "    if hasattr(func, \"python_function\"):\n",
    "        func = func.python_function\n",
    "    code = tf.autograph.to_code(func)\n",
    "    display(Markdown('```python\\n{}\\n```'.format(code)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def tf__add(x):\n",
       "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
       "        do_return = False\n",
       "        retval_ = ag__.UndefinedReturnValue()\n",
       "\n",
       "        def get_state():\n",
       "            return (x,)\n",
       "\n",
       "        def set_state(vars_):\n",
       "            nonlocal x\n",
       "            (x,) = vars_\n",
       "\n",
       "        def loop_body(itr):\n",
       "            nonlocal x\n",
       "            i = itr\n",
       "            x = ag__.ld(x)\n",
       "            x += 1\n",
       "        i = ag__.Undefined('i')\n",
       "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
       "        try:\n",
       "            do_return = True\n",
       "            retval_ = ag__.ld(x)\n",
       "        except:\n",
       "            do_return = False\n",
       "            raise\n",
       "        return fscope.ret(retval_, do_return)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_tf_code(add_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TF Functions with tf.keras (or Not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, tf.keras will automatically convert your custom code into TF Functions, no need to use\n",
    "`tf.function()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function\n",
    "def my_mse(y_true, y_pred):\n",
    "    print(\"Tracing loss my_mse()\")\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric function\n",
    "def my_mae(y_true, y_pred):\n",
    "    print(\"Tracing metric my_mae()\")\n",
    "    return tf.reduce_mean(tf.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.biases = self.add_weight(name='bias', \n",
    "                                      shape=(self.units,),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        print(\"Tracing MyDense.call()\")\n",
    "        return self.activation(X @ self.kernel + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model\n",
    "class MyModel(keras.models.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = MyDense(30, activation=\"relu\")\n",
    "        self.hidden2 = MyDense(30, activation=\"relu\")\n",
    "        self.output_ = MyDense(1)\n",
    "\n",
    "    def call(self, input):\n",
    "        print(\"Tracing MyModel.call()\")\n",
    "        hidden1 = self.hidden1(input)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_(concat)\n",
    "        return output\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "363/363 [==============================] - ETA: 0s - loss: 1.3790 - my_mae: 0.8028Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "363/363 [==============================] - 5s 9ms/step - loss: 1.3790 - my_mae: 0.8028 - val_loss: 0.4848 - val_my_mae: 0.4801\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.4405 - my_mae: 0.4778 - val_loss: 1.0984 - val_my_mae: 0.4742\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4185 - my_mae: 0.4662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4185033142566681, 0.4662216901779175]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can turn this off by creating the model with `dynamic=True` (or calling `super().__init__(dynamic=True, **kwargs)` in the model's constructor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the custom code will be called at each iteration. Let's fit, validate and evaluate with tiny datasets to avoid getting too much output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.622330665588379, 2.0634589195251465]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(X_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can compile a model with `run_eagerly=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.578635215759277, 2.06392240524292]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(X_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining custom optimizers is not very common, but in case you are one of the happy few who gets to write one, here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMomentumOptimizer(keras.optimizers.Optimizer):\n",
    "    def __init__(self, learning_rate=0.001, momentum=0.9, name=\"MyMomentumOptimizer\", **kwargs):\n",
    "        \"\"\"Call super().__init__() and use _set_hyper() to store hyperparameters\"\"\"\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate)) # handle lr=learning_rate\n",
    "        self._set_hyper(\"decay\", self._initial_decay) # \n",
    "        self._set_hyper(\"momentum\", momentum)\n",
    "    \n",
    "    def _create_slots(self, var_list):\n",
    "        \"\"\"For each model variable, create the optimizer variable associated with it.\n",
    "        TensorFlow calls these optimizer variables \"slots\".\n",
    "        For momentum optimization, we need one momentum slot per model variable.\n",
    "        \"\"\"\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, \"momentum\")\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        \"\"\"Update the slots and perform one optimization step for one model variable\n",
    "        \"\"\"\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype) # handle learning rate decay\n",
    "        momentum_var = self.get_slot(var, \"momentum\")\n",
    "        momentum_hyper = self._get_hyper(\"momentum\", var_dtype)\n",
    "        momentum_var.assign(momentum_var * momentum_hyper - (1. - momentum_hyper)* grad)\n",
    "        var.assign_add(momentum_var * lr_t)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "            \"decay\": self._serialize_hyperparameter(\"decay\"),\n",
    "            \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 4.2370\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.3922\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.7916\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6449\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.6028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2352a8d45e0>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([keras.layers.Dense(1, input_shape=[8])])\n",
    "model.compile(loss=\"mse\", optimizer=MyMomentumOptimizer())\n",
    "model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. to 11.\n",
    "See Appendix A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Implement a custom layer that performs _Layer Normalization_\n",
    "_We will use this type of layer in Chapter 15 when using Recurrent Neural Networks._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "_Exercise: The `build()` method should define two trainable weights *α* and *β*, both of shape `input_shape[-1:]` and data type `tf.float32`. *α* should be initialized with 1s, and *β* with 0s._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: see below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "_Exercise: The `call()` method should compute the mean_ μ _and standard deviation_ σ _of each instance's features. For this, you can use `tf.nn.moments(inputs, axes=-1, keepdims=True)`, which returns the mean μ and the variance σ<sup>2</sup> of all instances (compute the square root of the variance to get the standard deviation). Then the function should compute and return *α*⊗(*X* - μ)/(σ + ε) + *β*, where ⊗ represents itemwise multiplication (`*`) and ε is a smoothing term (small constant to avoid division by zero, e.g., 0.001)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(keras.layers.Layer):\n",
    "    def __init__(self, eps=0.001, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(\n",
    "            name=\"alpha\", shape=batch_input_shape[-1:],\n",
    "            initializer=\"ones\")\n",
    "        self.beta = self.add_weight(\n",
    "            name=\"beta\", shape=batch_input_shape[-1:],\n",
    "            initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        return self.alpha * (X - mean) / (tf.sqrt(variance + self.eps)) + self.beta\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"eps\": self.eps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that making _ε_ a hyperparameter (`eps`) was not compulsory. Also note that it's preferable to compute `tf.sqrt(variance + self.eps)` rather than `tf.sqrt(variance) + self.eps`. Indeed, the derivative of sqrt(z) is undefined when z=0, so training will bomb whenever the variance vector has at least one component equal to 0. Adding _ε_ within the square root guarantees that this will never happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "_Exercise: Ensure that your custom layer produces the same (or very nearly the same) output as the `keras.layers.LayerNormalization` layer._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create one instance of each class, apply them to some data (e.g., the training set), and ensure that the difference is negligeable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.894674e-08>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train.astype(np.float32)\n",
    "\n",
    "custom_layer_norm = LayerNormalization()\n",
    "keras_layer_norm = keras.layers.LayerNormalization()\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep, that's close enough. To be extra sure, let's make alpha and beta completely random and compare again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.7224725e-08>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_alpha = np.random.rand(X.shape[-1])\n",
    "random_beta = np.random.rand(X.shape[-1])\n",
    "\n",
    "custom_layer_norm.set_weights([random_alpha, random_beta])\n",
    "keras_layer_norm.set_weights([random_alpha, random_beta])\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
    "    keras_layer_norm(X), custom_layer_norm(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still a negligeable difference! Our custom layer works fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Train a model using a custom training loop to tackle the Fashion MNIST dataset\n",
    "_The Fashion MNIST dataset was introduced in Chapter 10._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "_Exercise: Display the epoch, iteration, mean training loss, and mean accuracy over each epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255.\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test.astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a27105a99e45d3820c683966e6792c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb3be1f9bad408e8a3b357de75b4b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc8c28ba28c4c98a68494f13e261147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e70ea0fbc364b0ba14835742995df67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065f15e09e6c4f8f839a001075dc6281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7984c40fbce4c84b9066b8f90b8025a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))                    \n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "_Exercise: Try using a different optimizer with a different learning rate for the upper layers and the lower layers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_layers = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "])\n",
    "upper_layers = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model = keras.models.Sequential([\n",
    "    lower_layers, upper_layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_optimizer = keras.optimizers.SGD(learning_rate=1e-4)\n",
    "upper_optimizer = keras.optimizers.Nadam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ed9389fd3345a2bd3231dfbf592a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c1c3f1ef604df0b19ba58f721fd4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a30d156c524214a355f811dc3e5bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48bd60ef5014914ab5da48adb5c3d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4300a463ae94301834d56e22f410a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1662e34fa439434991549985fe537a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                for layers, optimizer in ((lower_layers, lower_optimizer),\n",
    "                                          (upper_layers, upper_optimizer)):\n",
    "                    gradients = tape.gradient(loss, layers.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, layers.trainable_variables))\n",
    "                del tape\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))                    \n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(keras.metrics.sparse_categorical_accuracy(\n",
    "                tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('handson-ml2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "73638af37a8bd63ac5aa49b43d9b5fe96d96af13458e5a1ea8214600d93fc01b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
